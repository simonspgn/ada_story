---
layout: post
title: "A Data Analysis on Political Popularity and Media Coverage"
subtitle: "EPFL Applied Data Analysis Final Project"
date: 2021-12-10 23:45:13 -0400
background: '/img/posts/elections4.jpg'
---

Welcome to Team SARS' final ADAmazing project. In this study, we analyze the intricate relationship between voting intentions and media coverage in the past three US presidential elections. We find that...

# Background
It is often argued that former US president Donald Trump’s upset victory in the 2016 elections strongly relates to his ability to monopolize the attention of mass media outlets [1]. Although the former president’s polemical nature granted him a front row seat at almost every (inter)national newspaper in the months and years preceding the election [2], it can be a difficult task to assess the impact that such incessant media coverage had on the final outcome of the presidential elections. This is precisely the question that we aim to answer in the following study. We use the quotebank corpus to analyse possible correlations and causations between the media coverage of three different major outlets with notoriously distinct political inclinations: CNN (democrat), BBC (centrist) and Fox News (republican) as well as voting intentions in the months preceding each elections.

One of the first questions that we were faced with related to finding accurate means of quantifying media coverage and voting intentions. As such, we define the following:

* **Media Coverage**: defined in our study by the number of occurrences of keywords (such as a presidential candidate's name or his/her running mate) during a given presidential election in a given newspaper (BBC, NY Times or Fox News).

* **Voting Intentions**: defined in our study by poll numbers for each presidential candidate in the months prior to a given election.

# A visual tour of media coverage & voting intentions
In this section, we present a visual description of the data parsing and manipulations performed in order to begin our study.

## Media Coverage
Retrieving media coverage was done solely through the Quotebank dataset [3]. We started by retrieving all the quotations for the years in which a presidential election occurred (2012, 2016 and 2020) and which originated from one of the following three newspapers: NYTimes, Fox News, BBC (done by checking the origin of each link in the dataset's url column).

For each of the parsed quotation, we kept only those that included at least one occurrence of the presidential candidates names (or their running mates) within the quotation, the speaker or the url attributes of the dataset. Finally, we built timelines of the retrieved occurrence for each of the three aforementioned newspapers in the months preceding the presidential elections (January - November) in 2012, 2016 and 2020.

We start by presenting a visualization regarding the number of mentions per month for each newspaper that we have retrieved when parsing the data. This part does not focus on the candidates but rather on the overall occurrences of any keyword of interest per newspaper.

<iframe src="/ada_story/img/posts/newspapers_over_years.html" height="500px" width="100%" frameBorder="0"></iframe>

This initial visualization gives us several important insights for our study:

* **First**: the data for the 2012 elections that we retrieved is fairly well represented with generally more mentions in the NY Times, somewhat closely followed by Fox News and finally by BBC which (as expected) has the least mentions- we believe that BBC should have the least mentions because it isn't a natively American newspaper and since it is generally regarded as a more "centrist" leaning - in contrast to NY Times that is typically democrat leaning and Fox News that is republican leaning.

* **Second**: we are missing a considerable amount of data for the months of January-June, October 2016 and May-November 2020. This could potentially mean that there are only very few mentions in the newspapers we target (which seems highly unlikely considering the general fuss in the months leading to the elections and by comparing it with the 2012 data retrieved). A more plausible explanation refers to the quality of the Quotebank dataset, simply missing relevant quotations in these months. Concerning 2020, we noted that the Quotebank data retrieval ended in April 2020 [3], which confirms our observation. Concerning the 2016, we note in the visualization below that the missing data is simply caused by the poor nature of the dataset.

<iframe src="/ada_story/img/posts/bubble_2016_statistics.html" height="500px" width="100%" frameBorder="0"></iframe>

We illustrate in the bubble chart the total number of quotations present in the Quotebank dataset for a given newspaper in a given month (indicated by the larger transparent bubbles) versus the number of quotations retrieved that include any of our keywords of insterest (presidential candidate name or running mate name) for a given newspaper in a given month. We distinctly note that the Quotebank dataset exhibits very few total quotations for any of the newspapers in the months of January to June (inclusive) and October. To this observation we add the fact that the authors of Quotebank mention that.... [ANTOINE WHERE DID YOU FIND IT IN THE PAPER - ADD HERE]


We then proceed in our analysis by visualizing the distribution of mentions per candidate retrieved for the three years of interest (independently of the newspaper in which the mention occurred). We see in the visualization below a very interesting trend in which the republican candidates are generally more represented/mentioned in the three elections (without distinguishing between newspapers). Although the difference between Obama and Romney remains somewhat limited, the few months we can observe in the 2016 and 2020 elections show a complete disproportion in coverage between Trump and the democratic candidate.

<iframe src="/ada_story/img/posts/candidates_over_year.html" height="500px" width="100%" frameBorder="0"></iframe>

It is also interesting to note the overall difference between the republican and the democratic candidate over the span of the three elections. In 2012, we found 2695 more quotation referring to the republican candidate (Mitt Romney) than the democratic candidate (Barack Obama). This number is then increased almost two-fold (5460 quotations in 2016 and 4245 quotations in 2020) for the 2016 and 2020 elections. Even considering all the missing data in our set for 2016 and 2020, this is a notable difference that may be even more drastic with a full dataset. Such an observation may raise the question on whether the arrival of Donald Trump as a presidential candidate motivated an increase in media coverage difference between republican and democratic candidate.

We can further delve into the difference in coverage between republican and democratic candidate by visualizing the distribution of quotations referring to each candidate on a newspaper basis.

<iframe src="/ada_story/img/posts/candidates_over_year_newspaper.html" height="500px" width="100%" frameBorder="0"></iframe>

We see that tendency previously mentioned to predominantly cover a republican candidate is not necessarily true for 2012: although NYTimes (a notoriously Democrat newspaper) shows stronger media coverage for Mitt Romney, we note that Fox News (a notoriously Republican newspaper) shows slightly higher media coverage for Barack Obama. This is a very interesting behavior that is not apparent when looking only at overall mentions across all newspapers.

The only month in 2012 in which Barack Obama was given more NYTimes media coverage was in May. We also see that the highest democratic candidate coverage in the Fox News newspaper was during that same month. Can these peaks be attributed to a particular event? After a quick online search we found that in May 2012, Barack Obama became the first sitting US president to announce support for same-sex marriage [4]. Could these events be related? A more fined grain analysis may reveal correlation between these two events.

Nevertheless, in 2016 and 2020, the republican candidate always gets more media coverage than the democratic one.

## Voting Intentions

After scraping the polls the voting intentions taken from different surveys accross the United States from January 2012/2016/2020 to November 2012/2016/2020, we’ve plotted the line plots per candidate and per year

<iframe src="/ada_story/img/posts/voting_intentions_allyears.html" height="500px" width="100%" frameBorder="0"></iframe>

# Getting our hands dirty

We perform the correlation study here. We first start by a baseline model in which we compare media coverage and voting intentions on a per week? basis. We use regression analysis/statistical tests.... FILL IN HERE
We then further the analysis by including sentiment analysis as a covariate.... FILL IN HERE

In this section, we’ll study the correlation between the media coverage quantified and the voting intentions. First we’ve implemented a very simple baseline model… and then we’ve enhanced it by using unsupervised sentiment analysis…

There are several timeframe levels (such as year, month, week and day) in which we can aggregate the results for each combination of election year, candidate, and newspaper. If we aggregate by year we will have 1 data point only, by month 12 data points at most and 3 in the worst case (because some months will be discarded due to the small amount of occurrences). Due to the lack of data in 2016 and 2020 we found that the it may be a better  compromise between number of occurrences per period of time and the number of data points is achieved when we aggregate by week. The aggregation is performed as follows: take the mean of intention votes over the week (by choosing the end date of the poll to specify the week), and the occurrences will be rescaled by taking the occurrences of quotes for a specific combination over the week and dividing it by the total number of quotations in the specific week and newspaper.

## Baseline Correlation Study Between Media Coverage & Voting intentions

NOTE: Since we use a p-value to confirm/reject our correlation study, we may have to expressively describe what the null hypothesis is.

We started our correlation study by applying Spearman's rank correlation analysis between the media coverage rescaled (EXPLAIN HERE) and the voting intentions for each candidate in a given newspaper. We choose this metric as we noted that the media coverage variable is not normally distributed thus.... (EXPAND HERE - What does it mean? What's the implication of not having a normally distributed media coverage? Why could we not use other models?). We view our model as having intention vote as the dependent variable and media coverage as the predictor. The correlation results are illustrated in the chart below. Note that correlations in which the p-value is smaller than 0.05 (cases in which our hypothesis is statistically significant) are marked with dotted patterns to distinguish them from p-values that cannot be rejected (>0.05). We also note that the correlation study for 2016 and 2020 is performed only for the months in which we deemed to have enough media coverage data (2016: July, August, September; 2020: January, February, March, April). We did not include any specific statistical study or threshold to pick the months with "enough" data. Rather, we pick these months based on the visualizations presented in the previous section.

<iframe src="/ada_story/img/posts/baseline_correlation.html" height="500px" width="100%" frameBorder="0"></iframe>

We note a few interesting observations:

  * For candidate Barack Obama, Fox News exhibits a negative correlation between the media coverage and voting intentions, but this result is not statistically significant (all values are higher than 0.1 - ALL VALUES HIGHER THAN 0.1? What do you mean Raphael?).
  * For candidate Mitt Romney, all three newspapers produce positive correlations between media coverage and voting intentions, this result is a strong indication of a correlation (note that the p values are 0.010052, 0.000543 and 0.051361 for NY Times, Fox News respectively). Thus, concerning the 2012 elections, we may observe a correlation between media coverage and voting intentions for candidate Romney. However, nothing can be concluded for candidate Obama.
  * For candidate Hillary Clinton we note almost no correlation for the three newspapers. Since the p-values are higher than our confidence interval, we cannot reject the null hypothesis in any of these cases (all values are higher than 0.1 - HERE TOO).
  * For candidate Donald Trump in 2016,  we observe negative correlations in all three newspapers. In NY times, we observe a small enough p-value (0.0238) to reject the null hypothesis, which could possibly indicate a (negative) correlation - i.e media coverage may have had a negative impact on voting intentions. Nonetheless, the same cannot be said for the other two newspapers in which we witness p-values that prohibit us from rejecting the null hypothesis.
  * For candidate Joe Biden, although we note general positive correlations between media coverage and voting intentions in the three newspapers, no conclusion can be draw as all correlations exhibit a p-value higher than the 0.05 threshold. The null hypothesis cannot be rejected. A similar argument can be made for candidate Donald Trump in 2020. We not positive correlations for BBC and Fox News as well as a negative correlation for NY Times. However, since the p-values are all higher than our threshold, we cannot reject the null hypothesis.

This first baseline correlation study illustrates interesting behaviors. Concerning the statistically significant case of candidate Donald Trump in 2016's NY Times magazine, we note a negative correlation between media coverage and voting intentions. This observation is even more interesting when considering the colliding political inclinations of both the NY Times magazine and Donald Trump. In a purely rational sense, this behavior seems to fit the idea that a left-leaning newspaper would do everything to undermine the popularity of a republican candidate. This argument can also be made for candidate Mitt Romney's Fox News coverage.

Nevertheless, such argument cannot be made for the statistically significant positive correlation of Mitt Romney in the NY Times' magazine between media coverage and voting intentions. It would indeed seem strange that a left-leaning newspaper would positively contribute to the popularity of a republican candidate. A few hypothesis could potentially be made regarding the different political attitudes of both Donald Trump and Mitt Romney within the republican party. Since Donald Trump is generally regarded as a much more "extreme" candidate, one may think that it may have been easier for a left-leaning newspaper such as the NY Times to cover a rather moderate republican candidate such as Mitt Romney in a less passionate manner. This however, is insufficient to explain the high positive correlation witnessed (which could suggest that NY Times may have a interest in increasing Mitt Romney's popularity.

Talk about possible missing covariates and why the logical next step to improve this analysis is to include a sentiment analysis.

[adding the regression analysis : voting_intention = intercept + media_coverage ]

[adding a description of this study and the conclusion ]

## Adding Sentiment Analysis

Until now we've considered all candidate's name mentions with the same weight but we argue that two quotes with a
candidate's name mention can have very different effect based on positive or negative sentiment towards the candidate. Therefore, we want expand our analysis with an additional dimension : polarity.

Given our finite time, we have to assume some properties :

* [Sentiment soundness] We assume the aggregated sentiment of the quote reflect the general sentiment toward the
  candidate i.e there is a negligible number of hypocrite, humorous or 2nd degree quotes.
* [No external bias] QuoteBank is a non-biased sample of media coverage. This would be the case if QuoteBank was a
  complete set of all *words* used in the newspaper for the last 20 years, which is not feasible. QuoteBank is biased but we suppose for the sack of analysis its bias does not interfere.

As we don't have a labeled dataset, we opted for unsupervised sentiment analysis which unfortunately makes it difficult to assess the accuracy. On the other hand, manually labelling quotes (>10'000) would have been impossible in the given timeframe.

### Sentiment Classification

Our model will take text as input and output the sentiment associated to it.

1. text:- Actual quote
2. sentiment:- Floating value between -1 (negative) and +1 (positive).

### Preprocessing

We applied a simple preprocessing pipeline to the quotes to prepare them for sentiment analysis. The first step comes with removing the noises in the data; noise is referred to as something which not related to textual human language, and those come with various nature like special characters, use of parentheses, use of square brackets, white spaces, URL’s and punctuations.

Text normalisation starts with tokenizing the text, which our longer corpus is now to be split into words, which the
tokenizer class from NLTK can do. Post that, we need to lower case each word of our corpus, converting numbers to the words, contraction replacement and last stemming and lemmatization.

-- Pipeline --

* Remove punctuation
* Make text lowercase
* Tokenization
* Remove stopwords
* Stemming
* Lemmatization

### Sentiment Analysis Implementation

First let’s have a look the implementation of the unsupervised sentiment analysis on each quote that mentioned one of our candidates in 2012/2016/2020.

We tried three different unsupervised models :

* [VADER](https://github.com/cjhutto/vaderSentiment) (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and
  rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. It predicts
  the sentiment of the quote as a float, positive values are positive valence, negative value are negative valence.
* [Pre-trained BERT](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment) with >700 embeddings (
  bert-base-multilingual-uncased-sentiment). It predicts the sentiment of the review as a number of stars (between 1 and 5) and ensures 65% accuracy on their testing dataset.
* [TextBlob](https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis). It aims to provide access to
  common text-processing operations through a familiar interface. The polarity score is a float within the
  range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very
  subjective.

#### Model selection

Model selection was done using visualisation tools such as barplots, word-clouds (
see [exploratory_data_analysis.ipynb](exploratory_data_analysis.ipynb)). All further plots were done with the best
model (TextBlob) which provided the most interesting results and two metrics (with subjectivity)
instead of one. Furthermore, as we aggregate the data by month/by weeks for the correlation analysis, it was decided
more accurate to use numerical data instead of categorical as polarity score.

Processing was simply done by iterating over the dataset and applying the model to each quote.

Example:
**Original quote** : *Trump's a tough guy to vote for*.
**Preprocessed quote** : *trump tough guy vote*.
**Polarity/subjectivity score** : [-0.389, 0.834].

#### Model validation

![image](/ada_story/img/posts/wordcloud_2016.png)

![image 2](/ada_story/img/posts/wordcloud_2020.png)

![image 3](/ada_story/img/posts/wordcloud_2012.png)

Word-clouds sort the most present words by size. We partition the datasets for each year by positive/negative quotes and plot their respective word-clouds. We classify quotes with negative polarity valence (< -0.8) as negative and positive polarity valence (>0.8) as positive quotes. We can intuitively assess the precision of our model by looking at them. We observe a majority of ['great', 'good', 'win'] for positive quotes and ['worst', 'hate'] for negative quotes.

[ADD FREQUENCY DISTRIBUTION OF POLARITY AND SUBJECTIVITY SCORES OVER 2012, 2016, 2020]

We observe that a majority of quotes are analyzed as neutral (with respect to all models). This could be explained by a bias of the dataset as well as our sentiment analysis bias. We figured that the choice of stopwords to be removed from the strings is crucial to attributing positive or negative values.

#### Evolution of polarity & subjectivity score over months prior to election

We decide to compare vote intentions with aggregated polarity of quotes on a candidate/monthly basis. Let's plot the polarity and subjectivity distributions over time aggregated by month and candidate.

<iframe src="/ada_story/img/posts/polarity.html" height="500px" width="100%" frameBorder="0"></iframe>

<iframe src="/ada_story/img/posts/subjectivity.html" height="500px" width="100%" frameBorder="0"></iframe>

* Unfortunately, the change in polarity (y-axis) from a month to another is very small in most cases which makes it
difficult to conclude a meaningful statistical change. However we observe a very different timeline for 2016 election
due to missing data and quotes from 2020 don't extend past April.

<iframe src="/ada_story/img/posts/sentiment.html" height="500px" width="100%" frameBorder="0"></iframe>



### Correlation Results:
<iframe src="/ada_story/img/posts/sentiment_correlation.html" height="600px" width="110%" frameBorder="0"></iframe>

# So, did we find ADAstonishing results?

Conclude the study here

# References
[1] _https://www.politico.com/magazine/story/2016/11/2016-election-trump-media-takeover-coverage-214419/_  
[2] _https://www.bbc.co.uk/news/36429660.amp_  
[3] _https://dl.acm.org/doi/10.1145/3437963.3441760_  
[4] _https://obamawhitehouse.archives.gov/blog/2012/05/10/obama-supports-same-sex-marriage_  
